import cv2
import numpy as np
import os
import glob
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from torch.optim.lr_scheduler import CosineAnnealingLR
from sklearn.model_selection import StratifiedKFold
import pandas as pd
from tqdm import tqdm
import warnings

# å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Š
warnings.filterwarnings('ignore')

# ---------------------- 1. å…¨å±€é…ç½® (è¯·æ ¸å¯¹è·¯å¾„) ----------------------
CONFIG = {
    "img_size": 256,         # DenseNet æ¨èè¾“å…¥å°ºå¯¸
    "batch_size": 16,        # æ˜¾å­˜ä¸å¤Ÿå¯æ”¹ä¸º 8
    "epochs": 20,            # æ¯ä¸ª Fold è®­ç»ƒ 20 è½® (å¢åŠ å‡ è½®ä¿è¯æ”¶æ•›)
    "n_folds": 5,            # 5æŠ˜äº¤å‰éªŒè¯
    "lr": 1e-4,              # åˆå§‹å­¦ä¹ ç‡
    "seed": 2024,            # å›ºå®šéšæœºç§å­
    "num_workers": 0,        # Windowsä¸‹å»ºè®®è®¾ä¸º0ï¼Œé¿å…å¤šçº¿ç¨‹æŠ¥é”™
    # æ ¹æ®ä½ æŠ¥é”™ä¿¡æ¯å¡«å†™çš„è·¯å¾„ï¼Œæ— éœ€ä¿®æ”¹
    "train_root": r"D:\deeplearn\dataset-for-task2\dataset-for-task2\train",
    "test_root": r"D:\deeplearn\dataset-for-task2\dataset-for-task2\test",
    "submission_path": r"D:\deeplearn\dataset-for-task2\dataset-for-task2\submission.csv"
}

# æ¤ç‰©ç±»åˆ« (æŒ‰å­—æ¯é¡ºåºæ’åºï¼Œå¿…é¡»ä¸æ–‡ä»¶å¤¹é¡ºåºä¸€è‡´)
plant_classes = ['Black-grass', 'Common wheat', 'Loose Silky-bent', 'Scentless Mayweed', 'Sugar beet']

# ---------------------- 2. åŸºç¡€å·¥å…·å‡½æ•° ----------------------
def seed_everything(seed):
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(CONFIG['seed'])

def segment_plant(image):
    """
    HSV å»èƒŒæ™¯ç®—æ³•ï¼šæå–ç»¿è‰²æ¤ç‰©ï¼Œå°†èƒŒæ™¯ç½®é»‘
    """
    # è½¬æ¢åˆ° HSV ç©ºé—´
    hsv_img = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
    
    # ç»¿è‰²çš„ HSV èŒƒå›´ (å®½æ³›ä¸€ç‚¹ï¼Œé¿å…åˆ‡æ‰è¾¹ç¼˜)
    lower_green = np.array([25, 30, 30])
    upper_green = np.array([95, 255, 255])
    
    # ç”Ÿæˆæ©è†œ
    mask = cv2.inRange(hsv_img, lower_green, upper_green)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    
    # å åŠ æ©è†œ
    result = cv2.bitwise_and(image, image, mask=mask)
    return result

# ---------------------- 3. Dataset å®šä¹‰ ----------------------
class PlantDataset(Dataset):
    def __init__(self, img_paths, labels=None, transform=None, is_train=True):
        self.img_paths = img_paths
        self.labels = labels
        self.transform = transform
        self.is_train = is_train

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        path = self.img_paths[idx]
        # è¯»å–å›¾ç‰‡
        img = cv2.imread(path)
        if img is None:
            # å®¹é”™å¤„ç†
            img = np.zeros((CONFIG["img_size"], CONFIG["img_size"], 3), dtype=np.uint8)
        else:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # åº”ç”¨å»èƒŒæ™¯ (è¿™æ˜¯æåˆ†å…³é”®)
        img = segment_plant(img)
        
        # åº”ç”¨ PyTorch Transforms
        if self.transform:
            img = self.transform(img)
            
        if self.labels is not None:
            return img, self.labels[idx]
        else:
            # æµ‹è¯•é›†è¿”å›å›¾ç‰‡å’Œæ–‡ä»¶å
            return img, os.path.basename(path)

# ---------------------- 4. æ•°æ®å¢å¼ºä¸ Mixup ----------------------
def get_transforms(data):
    if data == 'train':
        return transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((CONFIG["img_size"] + 20, CONFIG["img_size"] + 20)),
            transforms.RandomCrop(CONFIG["img_size"]),
            transforms.RandomHorizontalFlip(),
            transforms.RandomVerticalFlip(),
            transforms.RandomRotation(30),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    elif data == 'valid':
        return transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((CONFIG["img_size"], CONFIG["img_size"])),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

# Mixup æ•°æ®å¢å¼ºï¼šå°†ä¸¤å¼ å›¾æŒ‰æ¯”ä¾‹å åŠ 
def mixup_data(x, y, alpha=0.4):
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1

    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)

    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

def mixup_criterion(criterion, pred, y_a, y_b, lam):
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

# ---------------------- 5. æ¨¡å‹å®šä¹‰ (DenseNet121) ----------------------
class PlantModel(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        # è‡ªåŠ¨ä¸‹è½½é¢„è®­ç»ƒæƒé‡
        self.backbone = models.densenet121(weights='DEFAULT')
        
        # ä¿®æ”¹åˆ†ç±»å±‚
        in_features = self.backbone.classifier.in_features
        self.backbone.classifier = nn.Sequential(
            nn.Linear(in_features, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
        
    def forward(self, x):
        return self.backbone(x)

# ---------------------- 6. è®­ç»ƒä¸éªŒè¯é€»è¾‘ (å·²ä¿®å¤æŠ¥é”™) ----------------------
def train_fn(model, loader, criterion, optimizer, device):
    model.train()
    running_loss = 0
    correct = 0 # Mixup ä¸‹ä»…ä¾›å‚è€ƒ
    total = 0
    
    # è¿›åº¦æ¡
    pbar = tqdm(loader, desc="Train", leave=False)
    
    for images, labels in pbar:
        # [FIX]: å¼ºåˆ¶è½¬æ¢ä¸º long ç±»å‹ï¼Œè§£å†³ RuntimeError
        images = images.to(device)
        labels = labels.to(device).long()
        
        # åº”ç”¨ Mixup
        images, targets_a, targets_b, lam = mixup_data(images, labels)
        
        optimizer.zero_grad()
        outputs = model(images)
        
        # è®¡ç®— Loss
        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item() * images.size(0)
        
        # ç®€å•ç»Ÿè®¡å‡†ç¡®ç‡
        _, preds = torch.max(outputs, 1)
        total += labels.size(0)
        # Mixup ä¸‹çš„å‡†ç¡®ç‡è¿‘ä¼¼è®¡ç®—
        correct += (lam * preds.eq(targets_a).cpu().sum().float() + (1 - lam) * preds.eq(targets_b).cpu().sum().float())
        
        pbar.set_postfix({'loss': running_loss/total})
        
    return running_loss / total, correct / total

def valid_fn(model, loader, criterion, device):
    model.eval()
    running_loss = 0
    correct = 0
    total = 0
    
    pbar = tqdm(loader, desc="Valid", leave=False)
    
    with torch.no_grad():
        for images, labels in pbar:
            # [FIX]: å¼ºåˆ¶è½¬æ¢ä¸º long ç±»å‹
            images = images.to(device)
            labels = labels.to(device).long()
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item() * images.size(0)
            _, preds = torch.max(outputs, 1)
            total += labels.size(0)
            correct += preds.eq(labels).cpu().sum().item()
            
            pbar.set_postfix({'acc': correct/total})
            
    return running_loss / total, correct / total

# ---------------------- 7. ä¸»å‡½æ•° ----------------------
def main():
    # æ£€æŸ¥æ˜¯å¦æœ‰ GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"âœ… è¿è¡Œè®¾å¤‡: {device}")
    if str(device) == 'cpu':
        print("âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ° GPUï¼Œè®­ç»ƒé€Ÿåº¦ä¼šéå¸¸æ…¢ï¼")

    # 1. è¯»å–æ‰€æœ‰æ•°æ®è·¯å¾„
    all_img_paths = []
    all_labels = []
    
    # éå†è®­ç»ƒé›†æ–‡ä»¶å¤¹
    print("ğŸ“‚ æ­£åœ¨è¯»å–æ•°æ®...")
    for idx, cls_name in enumerate(plant_classes):
        cls_dir = os.path.join(CONFIG["train_root"], cls_name)
        if not os.path.exists(cls_dir):
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶å¤¹ {cls_dir}")
            continue
            
        # å…¼å®¹å¤šç§å›¾ç‰‡æ ¼å¼
        paths = []
        for ext in ['*.png', '*.jpg', '*.jpeg']:
            paths.extend(glob.glob(os.path.join(cls_dir, ext)))
            
        all_img_paths.extend(paths)
        all_labels.extend([idx] * len(paths))
        
    all_img_paths = np.array(all_img_paths)
    all_labels = np.array(all_labels)
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {len(all_img_paths)}")
    
    if len(all_img_paths) == 0:
        print("âŒ é”™è¯¯: æ²¡æœ‰è¯»å–åˆ°ä»»ä½•å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥ CONFIG['train_root'] è·¯å¾„ï¼")
        return

    # 2. äº”æŠ˜äº¤å‰éªŒè¯å¾ªç¯
    skf = StratifiedKFold(n_splits=CONFIG["n_folds"], shuffle=True, random_state=CONFIG["seed"])
    best_fold_scores = []
    
    # å­˜å‚¨æ¨¡å‹æ–‡ä»¶åï¼Œæ–¹ä¾¿åç»­åŠ è½½
    model_files = []

    for fold, (train_idx, val_idx) in enumerate(skf.split(all_img_paths, all_labels)):
        print(f"\n{'='*15} Fold {fold+1} / {CONFIG['n_folds']} {'='*15}")
        
        # åˆ’åˆ†å½“å‰æŠ˜çš„æ•°æ®
        X_train, y_train = all_img_paths[train_idx], all_labels[train_idx]
        X_val, y_val = all_img_paths[val_idx], all_labels[val_idx]
        
        # æ„å»º Dataset å’Œ DataLoader
        train_ds = PlantDataset(X_train, y_train, transform=get_transforms('train'), is_train=True)
        val_ds = PlantDataset(X_val, y_val, transform=get_transforms('valid'), is_train=False)
        
        train_loader = DataLoader(train_ds, batch_size=CONFIG["batch_size"], shuffle=True, num_workers=CONFIG["num_workers"])
        val_loader = DataLoader(val_ds, batch_size=CONFIG["batch_size"], shuffle=False, num_workers=CONFIG["num_workers"])
        
        # åˆå§‹åŒ–æ¨¡å‹ã€ä¼˜åŒ–å™¨
        model = PlantModel(len(plant_classes)).to(device)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.AdamW(model.parameters(), lr=CONFIG["lr"], weight_decay=1e-4)
        scheduler = CosineAnnealingLR(optimizer, T_max=CONFIG["epochs"], eta_min=1e-6)
        
        best_acc = 0.0
        model_save_name = f"dense_fold_{fold}.pth"
        model_files.append(model_save_name)
        
        # è®­ç»ƒ Loop
        for epoch in range(CONFIG["epochs"]):
            train_loss, train_acc = train_fn(model, train_loader, criterion, optimizer, device)
            val_loss, val_acc = valid_fn(model, val_loader, criterion, device)
            scheduler.step()
            
            print(f"Epoch {epoch+1:02d} | Train Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f}")
            
            # ä¿å­˜æ¯ä¸€æŠ˜çš„æœ€ä½³æ¨¡å‹
            if val_acc > best_acc:
                best_acc = val_acc
                torch.save(model.state_dict(), model_save_name)
        
        print(f"ğŸ‰ Fold {fold+1} æœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}")
        best_fold_scores.append(best_acc)
        
    print(f"\nğŸ“ˆ æ‰€æœ‰ Fold å¹³å‡éªŒè¯å‡†ç¡®ç‡: {np.mean(best_fold_scores):.4f}")

    # ---------------------- 8. é›†æˆé¢„æµ‹ (Ensemble Inference) ----------------------
    print("\nğŸš€ å¼€å§‹é›†æˆé¢„æµ‹ (Ensemble Inference)...")
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_paths = []
    for ext in ['*.png', '*.jpg', '*.jpeg']:
        test_paths.extend(glob.glob(os.path.join(CONFIG["test_root"], ext)))
        
    if len(test_paths) == 0:
        print("âŒ é”™è¯¯: æµ‹è¯•é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")
        return

    test_ds = PlantDataset(test_paths, transform=get_transforms('valid'), is_train=False)
    test_loader = DataLoader(test_ds, batch_size=CONFIG["batch_size"]*2, shuffle=False, num_workers=CONFIG["num_workers"])
    
    # åˆå§‹åŒ–æ€»æ¦‚ç‡çŸ©é˜µ
    final_probs = np.zeros((len(test_paths), len(plant_classes)))
    
    # éå†æ‰€æœ‰è®­ç»ƒå¥½çš„ 5 ä¸ªæ¨¡å‹
    for fold in range(CONFIG["n_folds"]):
        print(f"æ­£åœ¨åŠ è½½ Fold {fold+1} çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹...")
        model = PlantModel(len(plant_classes)).to(device)
        model.load_state_dict(torch.load(model_files[fold]))
        model.eval()
        
        fold_probs = []
        with torch.no_grad():
            for images, _ in tqdm(test_loader, leave=False):
                images = images.to(device)
                
                # TTA ç­–ç•¥: é¢„æµ‹åŸå›¾ + é¢„æµ‹æ°´å¹³ç¿»è½¬å›¾
                out1 = model(images)
                out2 = model(torch.flip(images, [3])) # [Batch, C, H, W]ï¼Œdim=3 æ˜¯å®½åº¦æ–¹å‘
                
                # æ¦‚ç‡å–å¹³å‡
                probs = (torch.softmax(out1, 1) + torch.softmax(out2, 1)) / 2
                fold_probs.append(probs.cpu().numpy())
        
        # ç´¯åŠ å½“å‰æ¨¡å‹çš„é¢„æµ‹ç»“æœ
        final_probs += np.concatenate(fold_probs)
        
    # å– 5 ä¸ªæ¨¡å‹çš„å¹³å‡å€¼
    final_probs /= CONFIG["n_folds"]
    
    # è·å–æœ€ç»ˆç±»åˆ«
    predictions = np.argmax(final_probs, axis=1)
    pred_classes = [plant_classes[p] for p in predictions]
    img_names = [os.path.basename(p) for p in test_paths]
    
    # ---------------------- 9. ç”Ÿæˆæäº¤æ–‡ä»¶ ----------------------
    df = pd.DataFrame({'ID': img_names, 'Category': pred_classes})
    df.to_csv(CONFIG["submission_path"], index=False)
    
    print(f"\nâœ… é¢„æµ‹å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜è‡³: {CONFIG['submission_path']}")
    print("é¢„è§ˆå‰5è¡Œ:")
    print(df.head())

if __name__ == "__main__":
    main()